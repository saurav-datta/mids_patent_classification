{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Patent Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T09:44:42.999676Z",
     "start_time": "2018-08-02T09:44:14.962125Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import tensorflow as tf\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import gzip\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Input, Embedding, Reshape, Flatten, Conv1D, Conv2D, MaxPool2D, GlobalMaxPool1D, SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from keras import optimizers, models\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import keras_metrics\n",
    "import re\n",
    "import nltk\n",
    "from textblob import Word\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "\n",
    "https://www.google.com/googlebooks/uspto-patents-grants-text.html#2015\n",
    "\n",
    "The parsing and preprocessing of the patent files can be found here: \n",
    "\n",
    "https://github.com/cpapadimitriou/W266-Final-Project/blob/master/preparation/parse_xml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:52:37.754847Z",
     "start_time": "2018-08-02T07:51:57.975750Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "# features \n",
    "current_dir = %pwd\n",
    "abstract = pd.read_table(current_dir+'/out_zipped/docNumberToAbsText.txt.gz',compression='gzip', header=None)\n",
    "abstract = abstract[0].str.split('|', expand=True).rename(columns={0:'doc_num',1:'abstract'})\n",
    "\n",
    "claim = pd.read_table(current_dir+'/out_zipped/docNumberToClaimText.txt.gz',compression='gzip',  header=None)\n",
    "claim = claim[0].str.split('|', expand=True).rename(columns={0:'doc_num',1:'claim'})\n",
    "\n",
    "desc = pd.read_table(current_dir+'/out_zipped/docNumberToDescText.txt.gz',compression='gzip', header=None)\n",
    "desc = desc[0].str.split('|', expand=True).rename(columns={0:'doc_num',1:'desc'})\n",
    "\n",
    "title = pd.read_table(current_dir+'/out_zipped/docNumberToInvTitle.txt.gz',compression='gzip', header=None)\n",
    "title = title[0].str.split('|', expand=True).rename(columns={0:'doc_num',1:'title'})\n",
    "\n",
    "# file_name = pd.read_table(current_dir+'/out_zipped/fileNameToDocNumber.txt.gz',compression='gzip', header=None)\n",
    "# file_name = file_name[0].str.split('|', expand=True).rename(columns={0:'file_name',1:'doc_num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:52:38.137550Z",
     "start_time": "2018-08-02T07:52:37.756879Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels \n",
    "# label_names = pd.read_table(current_dir+'/out_zipped/docNumberToLabelSubClass.txt.gz',compression='gzip', header=None)\n",
    "# label_names = labels[0].str.split('|', expand=True).rename(columns={0:'doc_num'})\n",
    "\n",
    "labels = pd.read_table(current_dir+'/out_zipped/docNumberToLabelSubClassCode.txt.gz',compression='gzip', header=None)\n",
    "labels = labels[0].str.split('|', expand=True).rename(columns={0:'doc_num'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:52:38.591582Z",
     "start_time": "2018-08-02T07:52:38.139579Z"
    }
   },
   "outputs": [],
   "source": [
    "# joining the datasets\n",
    "X = pd.concat([title.set_index('doc_num'), \n",
    "           abstract.set_index('doc_num'), \n",
    "           claim.set_index('doc_num'), \n",
    "           desc.set_index('doc_num')], axis=1).sort_index() #  join='inner'\n",
    "\n",
    "Y = labels.set_index('doc_num').sort_index() #.set_index(X.index) # fixing the index mismatch\n",
    "Y.columns=[\"label{}\".format(i) for i in range(1,9)] # renaming columns \n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:52:46.674516Z",
     "start_time": "2018-08-02T07:52:38.593710Z"
    }
   },
   "outputs": [],
   "source": [
    "# data cleaning \n",
    "assert Y['label1'].isnull().sum() == 0 # there is no document with \n",
    "\n",
    "print(\"{} documents with null title\".format(X['title'].isnull().sum()))\n",
    "print(\"{} documents with null claims\".format(X['claim'].isnull().sum()))\n",
    "print(\"{} documents with null abstract\".format(X['abstract'].isnull().sum()))\n",
    "print(\"{} documents with null description\".format(X['desc'].isnull().sum()))\n",
    "\n",
    "# remove documents with null sections (title and abstract)\n",
    "X_clean = X.dropna(how='any')\n",
    "null_idx = X[~X.index.isin(X_clean.index)].index # storing the removed indices (i.e. document numbers)\n",
    "assert X.shape[0] - null_idx.shape[0] == X_clean.shape[0] # making sure the row counts match\n",
    "\n",
    "# removing the documents with null sections from the labels as well \n",
    "Y_clean = Y.loc[X_clean.index]\n",
    "\n",
    "# some checks\n",
    "assert X_clean.shape[0] == Y_clean.shape[0]\n",
    "assert ((Y_clean.index == X_clean.index)*1).sum() == X_clean.shape[0]\n",
    "\n",
    "# lower-casing everything\n",
    "X_clean = X_clean.apply(lambda x: x.str.lower())\n",
    "Y_clean = Y_clean.apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:52:51.605328Z",
     "start_time": "2018-08-02T07:52:46.676902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dataset \n",
    "data = pd.DataFrame()\n",
    "\n",
    "# concat the text of all patent sections and join the labels\n",
    "data['full_text'] = X_clean['title'] + \" \" + X_clean['claim'] + \" \" + X_clean['abstract'] + \" \" + X_clean['desc']\n",
    "\n",
    "# using only the first label  \n",
    "data['label1'] = Y_clean['label1'] \n",
    "\n",
    "# using all labels, merging them in a list and removing None values\n",
    "data['labels'] = Y_clean.values.tolist()\n",
    "data['labels'] = data['labels'].apply(lambda x: list(filter(None, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: we can potentially remove documents with less than 600 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:53:42.509587Z",
     "start_time": "2018-08-02T07:52:51.607729Z"
    }
   },
   "outputs": [],
   "source": [
    "# filtering out documents with fewer words \n",
    "data[\"doc_lenghts\"] = data.full_text.str.split().apply(lambda x: len(x))\n",
    "\n",
    "data[data[\"doc_lenghts\"]<600].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Labels with MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:53:47.447569Z",
     "start_time": "2018-08-02T07:53:42.511796Z"
    }
   },
   "outputs": [],
   "source": [
    "# converting labels into a binarized matrix with the labels as columns \n",
    "# and each patent document represented in one row\n",
    "mlb = preprocessing.MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['labels'])\n",
    "\n",
    "# checking that the conversion worked as desired by verifying the counts of labels for each document prior and post \n",
    "assert data['labels'].apply(lambda x: len(x)).values.sum() == np.array(pd.DataFrame(labels).apply(lambda x: x.sum(),axis=1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:53:47.451819Z",
     "start_time": "2018-08-02T07:53:47.449627Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# labels_df.iloc[:,[538]].sum()   #470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:54:17.249300Z",
     "start_time": "2018-08-02T07:54:17.228999Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(labels, columns=mlb.classes_)  #.apply(lambda x: x.sum(),axis=1)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:54:28.305608Z",
     "start_time": "2018-08-02T07:54:28.156582Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking how many times does each label (i.e. class) appear in the data \n",
    "# we observe that the classes are a little unbalanced \n",
    "pl = labels_df.apply(lambda x: x.sum(),axis=0).sort_values(ascending=False)  #.plot.bar()\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced text processing and TF_IDF \n",
    "Take the `data['full_text']` and for each patent return an observation with: \n",
    "- 600 most frequent words based on word frequency/tf_idf algorithm (make sure you do checks to ensure it is working properly\n",
    "- remove punctuation \n",
    "- lowercasing (happened earlier no need to do it here)\n",
    "- remove stop words \n",
    "- romove common / rare words\n",
    "- lemmatization or stemming\n",
    "- removing common words\n",
    "- remove digits (TO DO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:54:46.921092Z",
     "start_time": "2018-08-02T07:54:46.915712Z"
    }
   },
   "outputs": [],
   "source": [
    "data['full_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Advanced Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:56:09.364842Z",
     "start_time": "2018-08-02T07:55:23.469081Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing punctuation \n",
    "data['full_text_proc'] = data['full_text'].str.replace('[^\\w\\s]','')\n",
    "data['full_text_proc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T05:03:09.095458Z",
     "start_time": "2018-08-02T05:01:48.377940Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lower - casing \n",
    "#data['full_text_proc'] = data['full_text_proc'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:57:57.670854Z",
     "start_time": "2018-08-02T07:57:50.940713Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "# lower - casing \n",
    "data['full_text_proc'] = data['full_text_proc'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T07:59:39.168841Z",
     "start_time": "2018-08-02T07:59:32.672802Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "pattern_stop = r'\\b(?:{})\\b'.format('|'.join(stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:10:18.072380Z",
     "start_time": "2018-08-02T08:01:20.888274Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "data['full_text_proc_no_stop'] = data['full_text_proc'].str.replace(pattern_stop, '')\n",
    "data['full_text_proc_no_stop'] = data['full_text_proc_no_stop'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "#data['full_text_proc_no_stop'] = data['full_text_proc'].replace(to_replace=pattern_stop, value=\"\",regex=True)\n",
    "#data['full_text_proc_no_stop'] = data['full_text_proc_no_stop'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:11:40.656100Z",
     "start_time": "2018-08-02T08:11:40.612941Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "data['full_text_proc'] = data['full_text_proc_no_stop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T05:09:32.907859Z",
     "start_time": "2018-08-02T05:03:09.110433Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT] Handled in above cell already\n",
    "# removing stop words \n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# stop = nltk.corpus.stopwords.words('english')\n",
    "# data['full_text_proc'] = data['full_text_proc'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# data['full_text_proc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:16:46.550487Z",
     "start_time": "2018-08-02T08:15:23.611007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Common word removal \n",
    "# we can remove common words as their presence will not be of any use for our classification problem \n",
    "freq_words = pd.Series(' '.join(data['full_text_proc']).split()).value_counts()[:10] # chose the number here \n",
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:19:21.908270Z",
     "start_time": "2018-08-02T08:19:21.904598Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "freq_words = list(freq_words.index)\n",
    "pattern_freq_words = r'\\b(?:{})\\b'.format('|'.join(freq_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:21:34.147632Z",
     "start_time": "2018-08-02T08:19:37.008995Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "data['full_text_proc'] = data['full_text_proc'].replace(to_replace=pattern_freq_words, value=\"\",regex=True)\n",
    "data['full_text_proc'] = data['full_text_proc'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T05:09:32.910146Z",
     "start_time": "2018-08-02T04:57:58.909Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT] Handled in above cell already\n",
    "# Decide if we want to remove these\n",
    "# freq_words = list(freq_words.index)\n",
    "# data['full_text_proc'] = data['full_text_proc'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_words))\n",
    "# data['full_text_proc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:23:25.573565Z",
     "start_time": "2018-08-02T08:22:04.837387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rare word removal \n",
    "# Similarly, just as we removed the most common words, this time let’s remove rarely occurring words from the text. \n",
    "# Because they’re so rare, the association between them and other words is dominated by noise. \n",
    "rare_words = pd.Series(' '.join(data['full_text_proc']).split()).value_counts()[-10:]\n",
    "rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:25:07.132337Z",
     "start_time": "2018-08-02T08:25:07.129253Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "rare_words = list(rare_words.index)\n",
    "pattern_rare_words = r'\\b(?:{})\\b'.format('|'.join(rare_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:27:00.346657Z",
     "start_time": "2018-08-02T08:25:08.941475Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "data['full_text_proc'] = data['full_text_proc'].replace(to_replace=pattern_rare_words, value=\"\",regex=True)\n",
    "data['full_text_proc'] = data['full_text_proc'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T05:09:32.911809Z",
     "start_time": "2018-08-02T04:57:58.913Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT] Handled in above cell already\n",
    "# rare_words = list(rare_words.index)\n",
    "# data['full_text_proc'] = data['full_text_proc'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:36:00.274667Z",
     "start_time": "2018-08-02T08:36:00.269681Z"
    }
   },
   "outputs": [],
   "source": [
    "data['full_text_proc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T05:09:32.913946Z",
     "start_time": "2018-08-02T04:57:58.918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spelling correction (this will take a while to run - lets think if we need it. Maybe fo the foreign language words?)\n",
    "# Maybe there is another library to remove foreign language text? \n",
    "\n",
    "# from textblob import TextBlob\n",
    "# data['full_text_proc'] = data['full_text_proc'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T05:09:32.914833Z",
     "start_time": "2018-08-02T04:57:58.920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stemming: removal of suffices, like “ing”, “ly”, “s”, etc.\n",
    "# from nltk.stem import PorterStemmer\n",
    "# st = PorterStemmer()\n",
    "# data['full_text_proc'] = data['full_text_proc'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T09:02:41.194249Z",
     "start_time": "2018-08-02T08:44:45.823539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatization: converts the word into its root word, rather than just stripping the suffices.\n",
    "# use this instead of stemming \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from textblob import Word\n",
    "data['full_text_proc'] = data['full_text_proc'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['full_text_proc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:15:14.311965Z",
     "start_time": "2018-08-02T08:14:29.503199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Digits \n",
    "data['full_text_proc'] = data['full_text_proc'].apply(lambda x : re.sub(\"\\d+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T09:20:37.822339Z",
     "start_time": "2018-08-02T09:14:11.934414Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "#data.to_pickle('./saved_df_zipped/data_after_lemmatization.pkl.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T09:48:12.907631Z",
     "start_time": "2018-08-02T09:47:42.181747Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "#data = pd.DataFrame()\n",
    "#data = pd.read_pickle(\"./saved_df_zipped/data_after_lemmatization.pkl.gz\", compression='gzip')\n",
    "#data.info()\n",
    "#data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF (pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://medium.com/@acrosson/summarize-documents-using-tf-idf-bdee8f60b71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:44:35.331042Z",
     "start_time": "2018-08-02T10:44:35.327788Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:44:37.893869Z",
     "start_time": "2018-08-02T10:44:37.891430Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:44:41.369117Z",
     "start_time": "2018-08-02T10:44:41.366531Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:52:09.401052Z",
     "start_time": "2018-08-02T10:47:34.592774Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "count_vect = CountVectorizer(lowercase=True, analyzer='word',   \n",
    "                             stop_words='english', ngram_range=(1,1))\n",
    "count_vect = count_vect.fit(data['full_text_proc'])\n",
    "freq_term_matrix = count_vect.transform(data['full_text_proc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:52:32.474271Z",
     "start_time": "2018-08-02T10:52:32.165168Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(smooth_idf=False,sublinear_tf=False)\n",
    "tfidf.fit(freq_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:55:13.595354Z",
     "start_time": "2018-08-02T10:52:48.699550Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "doc_freq_term = count_vect.transform(data['full_text_proc'])\n",
    "doc_tfidf_matrix = tfidf.transform(doc_freq_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:59:59.458198Z",
     "start_time": "2018-08-02T10:59:58.091056Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "feature_names = np.array(count_vect.get_feature_names())\n",
    "feature_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T11:04:26.578260Z",
     "start_time": "2018-08-02T11:04:26.574198Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "doc_tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T11:35:54.444255Z",
     "start_time": "2018-08-02T11:31:46.569441Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "## This step has to be repeated in chunks till 78372 then appended into a single array\n",
    "\n",
    "doc_tfidf_matrix_dense_arr=doc_tfidf_matrix[range(0,1000),:].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "#Append command\n",
    "#doc_tfidf_matrix_dense=np.append(doc_tfidf_matrix_dense_tmp1,doc_tfidf_matrix_dense_tmp2,axis=0)doc_tfidf_matrix_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T11:01:13.749285Z",
     "start_time": "2018-08-02T11:01:13.727262Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "test_words = feature_names[np.argsort(doc_tfidf_matrix_dense)][:,-max_length:]\n",
    "test_words.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:57:25.702823Z",
     "start_time": "2018-08-02T10:57:25.689302Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "z = []\n",
    "for i,t in (enumerate(list(test_words))):\n",
    "    a = (set(t))\n",
    "    b = (set(re.sub(\"[^\\w]\", \" \",  (data['full_text_proc'][i])).split()))\n",
    "    z.append(list(a.intersection(b)))\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:56:32.782649Z",
     "start_time": "2018-08-02T10:56:32.759830Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201808012200 PT]\n",
    "data['full_text_proc_final'] = pd.Series(z, index=data.index).apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T10:28:58.826752Z",
     "start_time": "2018-08-02T10:28:58.769168Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF to eliminate word count\n",
    "# We can also perform basic pre-processing steps like lower-casing and removal of stopwords (but we did this earlier)\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=True, analyzer='word', smooth_idf=False, sublinear_tf=False, norm=None,\n",
    "                        stop_words='english', ngram_range=(1,1)) \n",
    "\n",
    "text_transformed = tfidf.fit_transform(data['full_text_proc']).toarray() # CHANGE THIS TO ALL DOCS\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "test_words = feature_names[np.argsort(text_transformed)][:,-max_length:]\n",
    "\n",
    "z = []\n",
    "for i,t in (enumerate(list(test_words))):\n",
    "    a = (set(t))\n",
    "    b = (set(re.sub(\"[^\\w]\", \" \",  (data['full_text_proc'][i])).split()))\n",
    "    z.append(list(a.intersection(b)))\n",
    "\n",
    "data['full_text_proc_final'] = pd.Series(z, index=data.index).apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T08:59:27.481833Z",
     "start_time": "2018-07-31T08:59:27.407250Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train test split \n",
    "# you can change to data['label1'] to include only the first label \n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data['full_text_proc_final'], labels, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:54:45.108606Z",
     "start_time": "2018-07-31T07:54:45.103591Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:54:45.113527Z",
     "start_time": "2018-07-31T07:54:45.110205Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Avg. number of labels in train set: {}\".format(Y_train.apply(lambda x: len(x)).mean()))\n",
    "# print(\"Avg. number of labels in test set: {}\".format(Y_test.apply(lambda x: len(x)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the pre-trained embeddings using this command:**\n",
    "\n",
    "`nohup curl -O https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M.vec.zip > curl.nohup.out 2>&1 &`\n",
    "\n",
    "Check loading progress with this: `cat curl.nohup.out`\n",
    "\n",
    "Unzipping the file with python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:54:45.119947Z",
     "start_time": "2018-07-31T07:54:45.115118Z"
    }
   },
   "outputs": [],
   "source": [
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length is set to 600 (we will choose the 600 most frequent words in each document)\n",
    "sequence_length = 600\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word-embeddings: representing documents using a dense vector representation\n",
    "# Word embeddings can be trained using the input corpus itself or \n",
    "# can be generated using pre-trained word embeddings such as Glove, FastText, and Word2Vec\n",
    "\n",
    "# step 1. Loading the pretrained word embeddings\n",
    "\n",
    "df_tmp1=pd.read_table('../wiki-news-300d-1M.vec.zip', compression='zip', sep='\\s+', header=None, engine='python', skiprows=1)\n",
    "columns=['word', 'vector']\n",
    "df_tmp2=pd.DataFrame(columns=columns)\n",
    "df_tmp2['word']=df_tmp1[df_tmp1.columns[0]]\n",
    "df_tmp2['vector']=np.asarray(df_tmp1[df_tmp1.columns[1:]], dtype='float32').tolist()\n",
    "embeddings_index=pd.Series(df_tmp2.vector.values, index=df_tmp2.word).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Tokenizer keras object: https://keras.io/preprocessing/text/\n",
    "\n",
    "This takes care of:\n",
    "- num of words to keep based on frequency (`num_words`).\n",
    "- filtering out punctuation: The **default** is all punctuation, plus tabs and line breaks, minus the ' character.\n",
    "- lower-casing: convert the texts to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:05:45.882848Z",
     "start_time": "2018-07-31T09:00:15.890336Z"
    }
   },
   "outputs": [],
   "source": [
    "# step 2. Creating a tokenizer object using Keras preprocessing object\n",
    "# the tokenizer has a default filter that removes all punctuation, plus tabs and line breaks, minus the ' character.\n",
    "token = text.Tokenizer(lower=True) # num_words=sequence_length\n",
    "token.fit_on_texts(data['full_text'])\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.706726Z",
     "start_time": "2018-07-31T07:52:51.148Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T08:08:09.371956Z",
     "start_time": "2018-07-31T08:08:09.368625Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of words in our vocabulary: {}'.format(len(word_index.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:15:24.929704Z",
     "start_time": "2018-07-31T09:10:25.433710Z"
    }
   },
   "outputs": [],
   "source": [
    "# step 3. Transforming text documents to sequence of tokens and padding them to ensure equal length vectors\n",
    "# choosing the median document length as max length for padding \n",
    "X_train_seq = sequence.pad_sequences(token.texts_to_sequences(X_train), maxlen=sequence_length)\n",
    "X_test_seq = sequence.pad_sequences(token.texts_to_sequences(X_test), maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out what this did to the first patent\n",
    "X_train_seq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:15:42.036274Z",
     "start_time": "2018-07-31T09:15:42.032419Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_seq.shape)\n",
    "print(X_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:15:51.243943Z",
     "start_time": "2018-07-31T09:15:50.882699Z"
    }
   },
   "outputs": [],
   "source": [
    "# step 4. Creating a mapping of tokens and their respective embeddings\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T08:17:54.565652Z",
     "start_time": "2018-07-31T08:17:54.561780Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positives (TP)**: the number of labels predicted by our approach (prediction labels) that\n",
    "matched the IPC labels (true labels), without taking the exact order into account.\n",
    "\n",
    "**False Positives (FP)**: the labels predicted by our approach (prediction labels) that do not match the true IPC labels. \n",
    "\n",
    "**False Negatives (FN)**: the labels that should have been predicted by our approach, but were not.\n",
    "\n",
    "**True Negatives (TN)**: the labels that, correctly, were not predicted by our approach. \n",
    "\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP + FP} = \\frac{trueLabels \\cap predictionLabels}{predictionLabels} $$\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP + FN} = \\frac{trueLabels \\cap predictionLabels}{trueLabels} $$\n",
    "\n",
    "**Precision** shows the ratio of the predicted labels that are true labels.\n",
    "\n",
    "**Recall** shows the ratio of the true labels that were predicted correctly. \n",
    "\n",
    "After calculating the above metrics for each patent document, we calculate the final Precision, Recall and F1-score across all documents as follows: \n",
    "\n",
    "$$Precision_{total} = \\frac{1}{TotalSamples} \\sum_{n=i}^{TotalSamples} Precision_i$$\n",
    "\n",
    "$$Recall_{total} = \\frac{1}{TotalSamples} \\sum_{n=i}^{TotalSamples} Recall_i$$\n",
    "\n",
    "$$F1_{total} = 2* \\frac{Precision_{total}*Recall_{total}}{Precision_{total}+Recall_{total}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:15:59.821929Z",
     "start_time": "2018-07-31T09:15:59.710647Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred): \n",
    "    \"\"\"Precision metric. Only computes a batch-wise average of precision.  \n",
    "     Computes the precision, a metric for multi-label classification of \n",
    "     how many selected items are relevant. \n",
    "     \"\"\" \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) \n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1))) \n",
    "    precision = true_positives / (predicted_positives + K.epsilon()) \n",
    "    return precision \n",
    "\n",
    "def recall(y_true, y_pred): \n",
    "    \"\"\"Recall metric. \n",
    "     Only computes a batch-wise average of recall. \n",
    "     Computes the recall, a metric for multi-label classification of \n",
    "     how many relevant items are selected. \n",
    "     \"\"\" \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) \n",
    "    recall = true_positives / (possible_positives + K.epsilon()) \n",
    "    return recall \n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definining Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** if we want to train our own embeddings we can try the `embeddings_initializer=\"uniform\"` parameter instead of `weights=[embedding_matrix]` in the embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:16:19.525147Z",
     "start_time": "2018-07-31T09:16:19.518709Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN Model Hyper-parameters \n",
    "vocabulary_size = len(word_index) + 1\n",
    "sequence_length = sequence_length\n",
    "embedding_dim = embedding_dim\n",
    "num_filters = 100\n",
    "#filter_sizes = [3]\n",
    "kernel_size = 3  \n",
    "\n",
    "units = Y_train.shape[1]  # we need the output nodes to equal the number of classes (96)\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:16:23.714291Z",
     "start_time": "2018-07-31T09:16:23.573179Z"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_model():    \n",
    "    \n",
    "    # Input Layer\n",
    "    input_layer = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "    # Word embedding Layer\n",
    "    embedding_layer = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=sequence_length, \n",
    "                                weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Convolutional Layer\n",
    "    conv_layer = Conv1D(num_filters, kernel_size=kernel_size, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Pooling Layer\n",
    "    pooling_layer = GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Output Layers\n",
    "    output_layer1 = Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = Dense(units= units, activation=\"sigmoid\")(output_layer1) \n",
    "\n",
    "    # Compile the model\n",
    "    # NOTE: we compile the model using binary cross entropy rather than categorical CE, since the goal \n",
    "    # is to treat each output labels as an independent Bernoulli distribution \n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2,)\n",
    "    model.compile(optimizer=optimizers.Adam(lr=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', recall, precision, f1]) # 'f1score', 'precision', 'recall'\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:37:11.932611Z",
     "start_time": "2018-07-31T09:37:11.927611Z"
    }
   },
   "outputs": [],
   "source": [
    "# LSTM Model Hyper-parameters \n",
    "vocabulary_size = len(word_index) + 1\n",
    "sequence_length = sequence_length\n",
    "embedding_dim = embedding_dim\n",
    "lstm_units = 100\n",
    "units = Y_train.shape[1] \n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T09:37:15.098660Z",
     "start_time": "2018-07-31T09:37:15.077941Z"
    }
   },
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "\n",
    "    # Input Layer\n",
    "    input_layer = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "    # Word embedding Layer\n",
    "    embedding_layer = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=sequence_length, \n",
    "                                weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = LSTM(lstm_units)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = Dense(units= units, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(lr=learning_rate), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', recall, precision, f1]) # 'f1score', 'precision', 'recall'\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: \n",
    "https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T10:03:06.840243Z",
     "start_time": "2018-07-31T09:47:19.164241Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201807310100 PT] Testing fit\n",
    "batch_size = 100\n",
    "epochs = 2\n",
    "\n",
    "# Choosing Model \n",
    "model_tmp = LSTM_model()  # CNN_model()\n",
    "model_tmp.summary()\n",
    "\n",
    "history_tmp = model_tmp.fit(X_train_seq, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T10:03:30.811941Z",
     "start_time": "2018-07-31T10:03:30.808029Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201807310100 PT] Testing fit\n",
    "history_tmp.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T10:24:19.884347Z",
     "start_time": "2018-07-31T10:24:19.671232Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201807310100 PT] Testing fit\n",
    "print(history_tmp.history['loss'])\n",
    "print(history_tmp.history['val_loss'])\n",
    "plt.plot(history_tmp.history['loss'])\n",
    "plt.plot(history_tmp.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T10:23:37.266884Z",
     "start_time": "2018-07-31T10:23:37.058742Z"
    }
   },
   "outputs": [],
   "source": [
    "#[201807310100 PT] Testing fit\n",
    "print(\"train accuracy:{}\".format(history_tmp.history['acc']))\n",
    "print(\"validation accuracy:{}\".format(history_tmp.history['val_acc']))\n",
    "plt.plot(history_tmp.history['acc'])\n",
    "plt.plot(history_tmp.history['val_acc'])\n",
    "plt.title('model train vs validation accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.716183Z",
     "start_time": "2018-07-31T07:52:51.171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Training Parameters \n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "# Choosing Model \n",
    "model = LSTM_model()  # CNN_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.716941Z",
     "start_time": "2018-07-31T07:52:51.173Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training LSTM\n",
    "history = model.fit(X_train_seq, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.717776Z",
     "start_time": "2018-07-31T07:52:51.175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Training Parameters \n",
    "batch_size = 100\n",
    "epochs = 40\n",
    "\n",
    "# Choosing Model \n",
    "model = CNN_model() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.718592Z",
     "start_time": "2018-07-31T07:52:51.176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training CNN\n",
    "history = model.fit(X_train_seq, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.719396Z",
     "start_time": "2018-07-31T07:52:51.178Z"
    }
   },
   "outputs": [],
   "source": [
    "# score = model.evaluate(X_test_seq, Y_test, verbose=0)\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.720188Z",
     "start_time": "2018-07-31T07:52:51.180Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pred_classes(X_test_seq, number_of_labels = 1):\n",
    "\n",
    "    preds = np.zeros(shape=model.predict(X_test_seq).shape)\n",
    "    pred_proba = model.predict(X_test_seq)\n",
    "\n",
    "    for i in range(pred_proba.shape[0]): \n",
    "        idxs = np.argsort(pred_proba[i])[::-1][:number_of_labels]\n",
    "        preds[i][idxs] = 1\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 1 label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.721003Z",
     "start_time": "2018-07-31T07:52:51.182Z"
    }
   },
   "outputs": [],
   "source": [
    "# average = samples : Calculate metrics for each instance, \n",
    "# and find their average (only meaningful for multilabel classification)\n",
    "pred_classes = get_pred_classes(X_test_seq, number_of_labels = 1)\n",
    "print(\"precision:\" , metrics.precision_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"recall:\" , metrics.recall_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"f1:\" , metrics.f1_score(Y_test, pred_classes, average = 'samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 2 labels prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.721801Z",
     "start_time": "2018-07-31T07:52:51.185Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_classes = get_pred_classes(X_test_seq, number_of_labels = 2)\n",
    "print(\"precision:\" , metrics.precision_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"recall:\" , metrics.recall_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"f1:\" , metrics.f1_score(Y_test, pred_classes, average = 'samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 labels prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.722612Z",
     "start_time": "2018-07-31T07:52:51.186Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_classes = get_pred_classes(X_test_seq, number_of_labels = 10)\n",
    "print(\"precision:\" , metrics.precision_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"recall:\" , metrics.recall_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"f1:\" , metrics.f1_score(Y_test, pred_classes, average = 'samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.723466Z",
     "start_time": "2018-07-31T07:52:51.188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ploting the loss \n",
    "#history.history[\"loss\"]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"precision\"], label=\"train_precision\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_precision\"], label=\"val_precision\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"recall\"], label=\"train_recall\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_recall\"], label=\"val_recall\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"f1\"], label=\"train_f1\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_f1\"], label=\"val_f1\")\n",
    "plt.title(\"Training Loss (LSTM)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid()\n",
    "#plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 1 label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.724271Z",
     "start_time": "2018-07-31T07:52:51.191Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_classes = get_pred_classes(X_test_seq, number_of_labels = 1)\n",
    "print(\"precision:\" , metrics.precision_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"recall:\" , metrics.recall_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"f1:\" , metrics.f1_score(Y_test, pred_classes, average = 'samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 2 labels prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.725119Z",
     "start_time": "2018-07-31T07:52:51.195Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_classes = get_pred_classes(X_test_seq, number_of_labels = 2)\n",
    "print(\"precision:\" , metrics.precision_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"recall:\" , metrics.recall_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"f1:\" , metrics.f1_score(Y_test, pred_classes, average = 'samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 labels prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.725945Z",
     "start_time": "2018-07-31T07:52:51.197Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_classes = get_pred_classes(X_test_seq, number_of_labels = 10)\n",
    "print(\"precision:\" , metrics.precision_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"recall:\" , metrics.recall_score(Y_test, pred_classes, average = 'samples'))\n",
    "print(\"f1:\" , metrics.f1_score(Y_test, pred_classes, average = 'samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.726757Z",
     "start_time": "2018-07-31T07:52:51.200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ploting the loss \n",
    "#history.history[\"loss\"]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"precision\"], label=\"train_precision\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_precision\"], label=\"val_precision\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"recall\"], label=\"train_recall\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_recall\"], label=\"val_recall\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"f1\"], label=\"train_f1\")\n",
    "# plt.plot(np.arange(0, N), history.history[\"val_f1\"], label=\"val_f1\")\n",
    "plt.title(\"Training Loss (CNN)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid()\n",
    "#plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.727522Z",
     "start_time": "2018-07-31T07:52:51.203Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X_test_seq)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:55:21.728304Z",
     "start_time": "2018-07-31T07:52:51.204Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(model.predict(X_test_seq)[i].argmax())\n",
    "#model.predict(X_test_seq)[4].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notify_time": "0",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
